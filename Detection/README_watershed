To make the bounding boxes, first we agrupate some events in a window of time.
Then we make the image as type uint8
then we binarize the image (grabing all events and turn then in 0)
then we apply a average filter in the image with a kernel size of (5,5), then we apply a median filter on the result.

This result is applied to the watershed method.
In that method I grab all the segmentation made by the watershed method and calculate the min and max of this uniques shapes that the watershed return to me.
In that method I put some feature as filtering the bounding boxes who are smaller then a threeshold (a percentage of the image, for default I put 2%, but you could change that if you want)

Then, I calculate the centroid of the bounding boxes and increment this information to our vector of bounding boxes
So, in this point we have a vector with the following informations for the bounding boxes:
[x, y, width, height, centroidx, centroidy]
Then I transform this for:
[x1, y1, x2, y2, centroidx, centroidy]

x1,y1 -> top-left
x2,y2 -> bottom-right

After change the way that my vector are, I call the function to filter the detections.
In this function I will iterate with every bounding box and check the IOU of each of one. If there is a IOU between the bounding box I merge then in one bigger one.
In this same function I apply the filter of centroid distances, so if the distance between the two bounding boxes is smaller then 50 pixels I merge then in one.

This is pretty much what I do. There is much to became better and improve, but we are trying to reach some robust method to segmentate the neuromorphic images. If you have any thougths about how we can make this work better, let me know, please.

Above I will put what you need of my git to apply my method in your system:

-> You will need of numpy, matplotlib.patches and openCV (take a look on the imports, but I think that somethings are not nedded to run the script and you could take off)
--> the file:
	--> https://github.com/eduardoborgesgouveia/HandStuff/blob/ubuntu/Detection/segmentationUtils.py
	--> https://github.com/eduardoborgesgouveia/HandStuff/blob/ubuntu/Detection/iou.py
	--> https://github.com/eduardoborgesgouveia/HandStuff/blob/ubuntu/Detection/filterUtils.py

Then you will agroupate your events and make an image (128,128)
then you will make:
	image = image.astype(np.uint8) #to asshore that your image is on uint8 type
My image usually have 3 values:
	127 to background
	255 to positive event of contrast
	0 to negative event of contrast
Then I change all events that are 255 to 0 and this is my process to binarizate the image
after this, I apply the avg filter and the median filter to the image using:

	imagem = filterUtils.avg(imagem)
        imagem = filterUtils.median(imagem)

after this I call my method of watershed using:

watershedImage, mask, detection = segmentationUtils.watershed(imagem,'--neuromorphic',minimumSizeBox=0.5,smallBBFilter=True,centroidDistanceFilter = True, mergeOverlapingDetectionsFilter = True)

	--> minimumSizeBox [optional]
	--> smallBBFilter [optional]
	--> centroidDistanceFilter [optional]
	--> mergeOverlapingDetectionsFilter [optional]

the 'detection' return is the list with all the bounding boxes that the method find.
the values are as type:
[x, y, width, length, centroidx, centroidy]

then, I use patches of matplotlib to print the bounding boxes using:

#patches receive (y,x), length and width
rect = patches.Rectangle((detection[j][1],detection[j][0]),detection[j][3],detection[j][2],linewidth=1,edgecolor='r',facecolor='none')
                    plt.gca().add_patch(rect)




In the file https://github.com/eduardoborgesgouveia/HandStuff/blob/ubuntu/Detection/classificationController.py you will be abble to see all my script, but he is a little bit messy.

If you want to talk about this, please send a message. I don't know if what I write is clear enough, but let me know if there is some doubt.




